# HLS Implementations of CNN Models

## Project Overview

This project provides C++ implementations of various Convolutional Neural Network (CNN) architectures, specifically designed and structured for High-Level Synthesis (HLS) targeting FPGAs (Field-Programmable Gate Arrays). The goal is to translate standard deep learning models into hardware-acceleratable descriptions using C++, leveraging tools like Vitis HLS or Vivado HLS.

Currently Included Models:
*   SqueezeNet v1.1
*   Xception

## High-Level Synthesis (HLS)

HLS allows developers to describe hardware functionality using higher-level languages like C, C++, or SystemC, rather than traditional Hardware Description Languages (HDLs) like Verilog or VHDL. This can significantly speed up the design cycle for complex algorithms like those found in deep learning.

However, writing C++ for HLS requires adherence to certain constraints:
*   **Static Memory Allocation:** Dynamic memory (`malloc`, `new`) is typically forbidden. All arrays (feature maps, weights) must have sizes known at compile time.
*   **Fixed-Point/Floating-Point:** While `float` is used here for simplicity, fixed-point data types are often preferred for better resource efficiency on FPGAs.
*   **Synthesizable Subset:** Not all C++ constructs are synthesizable (e.g., complex library functions, recursion, operating system calls).
*   **Explicit Parallelism:** HLS tools rely on pragmas (`#pragma HLS ...`) to guide optimizations like pipelining, loop unrolling, and memory partitioning for hardware parallelism.

### File Descriptions

*   **`[model_name]/`**: Contains all files specific to a particular CNN model.
*   **`[model_name]/Scripts/`**: Holds Python scripts used for preprocessing data or weights into a format suitable for the C++ HLS code.
    *   `generate_weights.py`: Downloads pre-trained model weights (using PyTorch/Torchvision) and formats them into C++ static arrays in the corresponding `_weights.h` file.
    *   `generate_input_image.py`: Loads an image (e.g., `.jpg`), preprocesses it (resize, normalize, mean subtraction, channel ordering), and formats it into a C++ static array in the corresponding `input_image*.h` file.
*   **`[model_name]/Test/`**: Contains raw input files used for testing (e.g., `dog.jpg`).
*   **`[model_name]/input_image*.h`**: C++ header file containing the preprocessed input image data as a large `static const float` array. Generated by a Python script.
*   **`[model_name]/[model_name]_params.h`**: Defines crucial compile-time constants for array sizes (input dimensions, feature map dimensions, buffer sizes, kernel sizes, channel counts). These are essential for static memory allocation in HLS.
*   **`[model_name]/[model_name]_weights.h`**: C++ header file containing the network's weights and biases as large `static const float` arrays. Generated by a Python script.
*   **`[model_name]/[model_name].h`**: Header file declaring the functions (layer implementations, top-level network function) defined in the corresponding `.cpp` file. Includes necessary headers and potentially activation function definitions.
*   **`[model_name]/[model_name].cpp`**: C++ source file containing the implementations of the neural network layers (convolution, pooling, activation, separable convolution, etc.) and the top-level function defining the network architecture dataflow. Contains HLS pragmas for optimization.
*   **`[model_name]/[model_name]_tb.cpp`**: C++ testbench used to simulate the HLS design. It typically includes the input data (`input_image*.h`), calls the top-level network function (`[model_name].h`), and checks or prints the output.
*   **`[model_name]/README.md`**: Provides specific details about the architecture of the model implemented in that folder.
*   **`HLSDEMO/README.md`**: This main README file.

## Running the Code

1.  **Prerequisites:**
    *   Xilinx Vitis HLS (or Vivado HLS) installed.
    *   A C++ compiler (like `g++`) for software simulation if desired outside HLS.
    *   Python 3.x installed.
    *   Required Python libraries: `torch`, `torchvision`, `numpy`, `Pillow` (`pip install torch torchvision numpy Pillow`).
2.  **Generate Weights & Input:**
    *   Navigate to the `Scripts` directory for the desired model (e.g., `cd SqueezeNet/Scripts`).
    *   Run the weight generation script: `python generate_weights.py`. Ensure `CPP_NUM_CLASSES` in the script matches `NUM_CLASSES` in `_params.h`.
    *   Run the input image generation script: `python generate_input_image.py`. Ensure it reads the correct source image and uses appropriate preprocessing.
3.  **Run HLS Simulation (CSim):**
    *   Open Vitis HLS GUI or use a Tcl script.
    *   Create a project for the desired model (e.g., SqueezeNet).
    *   Add the corresponding `.cpp`, `.h`, `_params.h`, and `_weights.h` files as design files.
    *   Add the `_tb.cpp` and generated `input_image*.h` files as testbench files.
    *   Set the top-level function (e.g., `SqueezeNet` or `Xception`).
    *   Set the target FPGA device and clock period.
    *   Run "C Simulation". Check the output for correctness (compare against a known framework like PyTorch if possible).
4.  **Run HLS Synthesis & Implementation:**
    *   Run "C Synthesis" to generate RTL (Verilog/VHDL). Analyze the reports for timing, latency, and resource utilization (LUTs, FFs, BRAM, DSPs).
    *   (Optional) Run "C/RTL Co-simulation" for further verification.
    *   (Optional) Export the RTL as an IP core for integration into a larger Vivado hardware design.

## Dependencies

*   Xilinx Vitis HLS (tested with 2022.2, adjust pragmas/settings for other versions)
*   Python 3.x
*   PyTorch
*   Torchvision
*   NumPy
*   Pillow (PIL Fork)